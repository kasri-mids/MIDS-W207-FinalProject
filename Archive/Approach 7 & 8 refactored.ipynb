{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Additional imports\n",
    "from sklearn import tree\n",
    "import xgboost as xgb\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "    IPython.OutputArea.auto_scroll_threshold = 9999\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "    IPython.OutputArea.auto_scroll_threshold = 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "pd.set_option('display.max_columns',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (15120, 54)\n",
      "label shape: (15120,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data.as_matrix(columns=data.columns[1:55]))\n",
    "Y = np.array(data[\"Cover_Type\"].tolist())\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "train_df = data.iloc[shuffle,:].iloc[:12000 , :]\n",
    "print('data shape: ', X.shape)\n",
    "print('label shape:', Y.shape)\n",
    "test_data, test_labels = X[13000:], Y[13000:]\n",
    "dev_data, dev_labels = X[12000:13000], Y[12000:13000]\n",
    "train_data, train_labels = X[:12000], Y[:12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModel():\n",
    "    \"\"\"\n",
    "    Parent class for all ML models\n",
    "    \"\"\"\n",
    "    def __init__(self, modelName='LogisticRegression'):\n",
    "        self.modelName = modelName\n",
    "        self.scaler = None\n",
    "        self.pca = None\n",
    "        if modelName == 'LogisticRegression':\n",
    "            self.model = LogisticRegression(penalty='l2', solver='newton-cg', tol=0.001,random_state=1,\n",
    "                                            multi_class='auto', max_iter=1000, verbose=0)\n",
    "        elif modelName == 'DecisionTree':\n",
    "            self.model = DecisionTreeClassifier(random_state=1)\n",
    "        elif modelName == 'RandomForest':\n",
    "            self.model = RandomForestClassifier(random_state=1)\n",
    "        elif modelName == 'GradientBoosting':\n",
    "            self.model = GradientBoostingClassifier(random_state=1)\n",
    "        elif modelName == 'KNearestNeighbor':\n",
    "            self.model = KNeighborsClassifier()\n",
    "        elif modelName == 'Xgboost':\n",
    "            self.model = xgb.XGBClassifier(random_state=1)\n",
    "        else:\n",
    "            raise Exception('Model ' + modelName + ' not implemented...')\n",
    "            \n",
    "    def grid_search(self, train_data, train_labels, dev_data, dev_labels, params, pca=None, scaler_type=None , print_out=True):\n",
    "        \n",
    "        grd_model = GridSearchCV( self.model,  param_grid = params ,return_train_score = 1, cv=3, n_jobs=-1)\n",
    "        if scaler_type is not None:\n",
    "            [scaled_train_data, scaled_dev_data] = self.scale_data(scaler_type ,  train_data , dev_data)\n",
    "            if pca is not None:\n",
    "                [scaled_train_pca_data, scaled_dev_pca_data] = self.pca_transform(scaled_train_data, scaled_dev_data, pca)\n",
    "                grd_model.fit(scaled_train_pca_data, train_labels)\n",
    "                predicted= grd_model.predict(scaled_dev_pca_data)\n",
    "            else:\n",
    "                grd_model.fit(scaled_train_data,train_labels)\n",
    "                predicted= grd_model.predict(scaled_dev_data)\n",
    "        else:\n",
    "            if pca is not None:\n",
    "                [train_pca_data, dev_pca_data] = self.pca_transform(train_data, dev_data, pca)\n",
    "                grd_model.fit(train_pca_data, train_labels)\n",
    "                predicted= grd_model.predict(dev_pca_data)\n",
    "            else:\n",
    "                grd_model.fit(train_data,train_labels)\n",
    "                predicted= grd_model.predict(dev_data)\n",
    "        if print_out != False:  \n",
    "            print ( \"\\033[1m\" ,  self.modelName , \"\\033[0;0m\" )\n",
    "            print (\"Best fit parameters :\")\n",
    "            print (grd_model.best_params_)\n",
    "            print (\"Best fit model F1 score :\")\n",
    "            print (metrics.f1_score(dev_labels, predicted , average='micro'))\n",
    "        self.classification_report = classification_report(predicted,dev_labels )       \n",
    "        self.best_model = grd_model\n",
    "        self.best_metrics = metrics.f1_score(dev_labels, predicted , average='micro')\n",
    "        \n",
    "    def scale_data(self, scaler_type ,  X_train , X_dev):\n",
    "        if scaler_type == 'MinMax' :\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        elif scaler_type == 'Robust':\n",
    "            scaler = RobustScaler()\n",
    "        elif scaler_type == 'Standard':\n",
    "            scaler = StandardScaler()\n",
    "        else:\n",
    "            print('Unrecognized scaler ' + scaler_type + ' ... reverting to MinMax')\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        scaled_X_train = scaler.fit_transform(X_train)\n",
    "        scaled_X_dev = scaler.transform(X_dev)\n",
    "        \n",
    "        self.scaler = scaler\n",
    "\n",
    "        return([scaled_X_train, scaled_X_dev])\n",
    "    \n",
    "    def pca_transform(self, X_train , X_dev, npca):\n",
    "        pcaModel = PCA(n_components=npca)\n",
    "        X_train_pca = pcaModel.fit_transform(X_train)\n",
    "        X_dev_pca = pcaModel.transform(X_dev)\n",
    "        return([X_train_pca, X_dev_pca])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First classify the output between two classes . Class 0 with covertype 1,2 . Class 1 with covertype with rest. Have 2 more models 2 classify to exact cover type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare train and dev data for model 1 \n",
    "test_model_1 = MLModel(modelName='RandomForest')\n",
    "test_model_2 = MLModel(modelName='RandomForest')\n",
    "test_model_3 = MLModel(modelName='RandomForest')\n",
    "pca_components = None\n",
    "scaler_type = None\n",
    "params = {  'n_estimators' : [ 20, 30 , 40 ,50 , 200 ]  }\n",
    "train_labels_ens_1 = np.where(train_labels> 2 , 1 , 0)\n",
    "dev_labels_ens_1 = np.where(dev_labels> 2 , 1 , 0)\n",
    "test_model_1.grid_search(train_data, train_labels_ens_1, dev_data, dev_labels_ens_1, params, pca=pca_components, scaler_type=scaler_type , print_out=False)\n",
    "train_labels_ens_2 = train_labels[np.where(train_labels <= 2)]\n",
    "train_data_ens_2 = train_data[np.where(train_labels <= 2)]\n",
    "test_model_2.grid_search(train_data_ens_2, train_labels_ens_2, dev_data, dev_labels, params, pca=pca_components, scaler_type=scaler_type , print_out=False)\n",
    "train_labels_ens_3 = train_labels[np.where(train_labels > 2)]\n",
    "train_data_ens_3 = train_data[np.where(train_labels > 2)]\n",
    "test_model_3.grid_search(train_data_ens_3, train_labels_ens_3, dev_data, dev_labels, params, pca=pca_components, scaler_type=scaler_type, print_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fit model F1 score :\n",
      "0.8619999999999999\n"
     ]
    }
   ],
   "source": [
    "def predict_approach_ensemble_7(data , labels , test_model_1 , test_model_2, test_model_3):\n",
    "    predicted_1 = test_model_1.best_model.predict(data)\n",
    "    predicted_2 = test_model_2.best_model.predict(data)\n",
    "    predicted_3 = test_model_3.best_model.predict(data)\n",
    "    predicted_final = np.empty(labels.size , dtype=int)\n",
    "    for i in range(labels.size):\n",
    "        if predicted_1[i] == 0:\n",
    "            predicted_final[i] = predicted_2[i]\n",
    "        else:\n",
    "            predicted_final[i] = predicted_3[i]\n",
    "    return predicted_final \n",
    "predicted = predict_approach_ensemble_7(dev_data , dev_labels , test_model_1 , test_model_2, test_model_3)\n",
    "print (\"Best fit model F1 score :\")\n",
    "print(metrics.f1_score(dev_labels, predicted , average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First classify the output into 6 classes 0 ,  3 , 4 , 5 , 6 , 7. 0 is a combined class for 1 and 2. Have a separate model to classify 1 and 2 covertypes. In case the first model predicts 0 , then use the second model to further classify it as 1 or 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_ens_1 = np.where(train_labels> 2 , train_labels , 0 )\n",
    "dev_labels_ens_1 = np.where(dev_labels> 2 , dev_labels , 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_1 = MLModel(modelName='RandomForest')\n",
    "test_model_2 = MLModel(modelName='RandomForest')\n",
    "pca_components = None\n",
    "scaler_type = None\n",
    "params = {  'n_estimators' : [ 20, 30 , 40 ,50 , 200 ]  }\n",
    "train_labels_ens_1 = np.where(train_labels> 2 , train_labels , 0 )\n",
    "dev_labels_ens_1 = np.where(dev_labels> 2 , dev_labels , 0)\n",
    "test_model_1.grid_search(train_data, train_labels_ens_1, dev_data, dev_labels_ens_1, params, pca=pca_components, scaler_type=scaler_type , print_out=False)\n",
    "train_labels_ens_2 = train_labels[np.where(train_labels <= 2)]\n",
    "train_data_ens_2 = train_data[np.where(train_labels <= 2)]\n",
    "test_model_2.grid_search(train_data_ens_2, train_labels_ens_2, dev_data, dev_labels, params, pca=pca_components, scaler_type=scaler_type , print_out=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fit model F1 score :\n",
      "0.865\n"
     ]
    }
   ],
   "source": [
    "def predict_approach_ensemble_8(data , labels , test_model_1 , test_model_2):\n",
    "    predicted_1 = test_model_1.best_model.predict(data)\n",
    "    predicted_2 = test_model_2.best_model.predict(data)\n",
    "    predicted_final = predicted_1\n",
    "    for i in range(predicted_1.size):\n",
    "        if predicted_1[i] == 0:\n",
    "            predicted_final[i] = predicted_2[i]\n",
    "    return predicted_final     \n",
    "predicted = predict_approach_ensemble_8(dev_data , dev_labels , test_model_1 , test_model_2)\n",
    "print (\"Best fit model F1 score :\")\n",
    "print(metrics.f1_score(dev_labels, predicted , average='micro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
